<!DOCTYPE html>
<html>
<head>
    <title>WebSocket 테스트</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start;
            min-height: 100vh;
            margin: 0;
            background-color: #f0f2f5;
            color: #333;
            padding: 20px;
            box-sizing: border-box;
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 2rem;
            text-align: center;
            font-size: 2.2em;
        }
        .section {
            background-color: #ffffff;
            border-radius: 12px;
            box-shadow: 0 6px 15px rgba(0, 0, 0, 0.1);
            padding: 30px;
            margin-bottom: 30px;
            width: 100%;
            max-width: 500px;
            box-sizing: border-box;
            text-align: center;
        }
        .section h2 {
            color: #34495e;
            margin-top: 0;
            margin-bottom: 20px;
            font-size: 1.5em;
        }
        button {
            background-color: #3498db;
            color: white;
            border: none;
            border-radius: 8px;
            padding: 15px 30px;
            margin: 10px;
            font-size: 1.1em;
            cursor: pointer;
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.2s ease;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            width: calc(50% - 20px);
            min-width: 120px;
        }
        button:hover {
            background-color: #2980b9;
            transform: translateY(-2px);
            box-shadow: 0 6px 10px rgba(0, 0, 0, 0.15);
        }
        button:active {
            transform: translateY(0);
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        #logBox {
            background: #1e1e1e;
            color: #eee;
            padding: 15px;
            border-radius: 8px;
            width: 100%;
            max-width: 600px;
            height: 300px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 0.9em;
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }
        .log-info { color: #3498db; }
        .log-success { color: #2ecc71; }
        .log-error { color: #e74c3c; }
        @media (max-width: 600px) {
            h1 { font-size: 1.8em; }
            .section { padding: 20px; margin-bottom: 20px; }
            button { width: calc(100% - 20px); margin: 8px 0; }
        }
    </style>
</head>
<body>
    <h1>FastAPI WebSocket 음성 수신 테스트</h1>

    <div class="section">
        <h2>마이크 스트리밍</h2>
        <div>
            <button onclick="startMicrophoneStream()">시작</button>
            <button onclick="stopMicrophoneStream()">중지</button>
        </div>
    </div>

    <div class="section">
        <h2>WebSocket 로그</h2>
        <div id="logBox"></div>
    </div>

    <script>
        let micWs;
        let micAudioContext;
        let micProcessor;
        let micInput;
        let currentStatus = 0; // 0: idle, 1: listening, 2: thinking, 3: speaking
        let isSpeaking = false; // speaking 상태 플래그

        function appendLog(message, type = 'info') {
            const logBox = document.getElementById('logBox');
            const p = document.createElement('div');
            p.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            p.classList.add(`log-${type}`);
            logBox.appendChild(p);
            logBox.scrollTop = logBox.scrollHeight;
        }

        function startMicrophoneStream() {
            if (micWs && micWs.readyState === WebSocket.OPEN) return;

            micWs = new WebSocket("wss://" + location.host + "/ws");
            micWs.binaryType = "arraybuffer";

            micWs.onopen = () => {
                appendLog("WebSocket 연결 성공.", "info");
                navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        /*channelCount: 1,
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false*/
                    }
                }).then(stream => {
                    // 초기 1초 음성 버퍼 버리기
                    discardInitialAudio(stream, 1).then(() => {
                        appendLog("초기 음성 버퍼 무시 완료, 음성 전송 시작", "info");

                        micAudioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                        micInput = micAudioContext.createMediaStreamSource(stream);
                        micProcessor = micAudioContext.createScriptProcessor(4096, 1, 1);

                        micInput.connect(micProcessor);
                        micProcessor.connect(micAudioContext.destination);

                        micProcessor.onaudioprocess = (e) => {
                            if (!isSpeaking && currentStatus !== 2) {
                                const inputData = e.inputBuffer.getChannelData(0);
                                const int16Data = float32ToInt16(inputData);
                                if (micWs.readyState === WebSocket.OPEN) {
                                    micWs.send(int16Data.buffer);
                                }
                            }
                        };
                    });
                })
                .catch(err => appendLog("마이크 접근 실패: " + err, "error"));
            };

            // discardInitialAudio 함수 정의
            function discardInitialAudio(stream, durationSec = 1) {
                return new Promise((resolve) => {
                    const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                    const micInput = audioCtx.createMediaStreamSource(stream);
                    const processor = audioCtx.createScriptProcessor(4096, 1, 1);

                    let elapsed = 0;
                    processor.onaudioprocess = (e) => {
                        elapsed += e.inputBuffer.length / audioCtx.sampleRate;
                        if (elapsed >= durationSec) {
                            processor.disconnect();
                            micInput.disconnect();
                            audioCtx.close();
                            resolve();
                        }
                    };

                    micInput.connect(processor);
                    processor.connect(audioCtx.destination);
                });
            }


            micWs.onmessage = async (msg) => {
                try {
                    let data;
                    try { 
                        data = JSON.parse(msg.data); 
                    } catch {
                        appendLog("서버: " + msg.data, "info");
                        return;
                    }

                    if (data.code !== undefined) currentStatus = data.code;

                    switch(currentStatus) {
                        case 0: // idle
                            appendLog("상태: idle, 마이크 전송 재개", "info");
                            break;
                        case 1: // listening
                            appendLog("상태: listening, 마이크 입력 수집 중", "info");
                            break;
                        case 2: // thinking
                            appendLog("상태: thinking, 마이크 전송 중지", "info");
                            break;
                        case 3: // speaking
                            appendLog("상태: speaking, 음성 재생", "info");
                            isSpeaking = true; // speaking 시작
                            if (data.audio_base64) {
                                const audioData = Uint8Array.from(atob(data.audio_base64), c => c.charCodeAt(0));
                                const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                                const buffer = await audioCtx.decodeAudioData(audioData.buffer);
                                const source = audioCtx.createBufferSource();
                                source.buffer = buffer;
                                source.connect(audioCtx.destination);

                                source.onended = () => {
                                    appendLog("음성 재생 완료, 마이크 전송 재개", "info");
                                    isSpeaking = false;     // speaking 종료
                                    currentStatus = 0;      // 상태 idle로 변경
                                };

                                source.start();
                            }
                            break;
                    }
                } catch(err) {
                    appendLog("메시지 처리 오류: " + err, "error");
                }
            };

            micWs.onerror = (error) => appendLog("WebSocket 오류: " + error, "error");
            micWs.onclose = () => appendLog("WebSocket 연결 종료", "info");
        }

        function stopMicrophoneStream() {
            if (micProcessor) { micProcessor.disconnect(); micProcessor = null; }
            if (micInput) { micInput.disconnect(); micInput = null; }
            if (micAudioContext) { micAudioContext.close(); micAudioContext = null; }
            if (micWs) { micWs.close(); micWs = null; }
            appendLog("마이크 음성 전송 중지.", "info");
        }

        function float32ToInt16(float32Array) {
            const int16Array = new Int16Array(float32Array.length);
            for (let i = 0; i < float32Array.length; i++) {
                let s = Math.max(-1, Math.min(1, float32Array[i]));
                int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return int16Array;
        }
    </script>

</body>
</html>
